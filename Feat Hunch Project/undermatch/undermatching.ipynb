{
 "metadata": {
  "name": "",
  "signature": "sha256:f565d32ace77ccb38d7c0077afd9965b08745b8555210f20b3985357fe120dc9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Author : Himabindu Lakkaraju\n",
      "\n",
      "\n",
      "Please route any queries to lvhimabindu@gmail.com"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Utility"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is an iPython notebook for determining the effect of a \"source\" variable on some \"target\" outcome. In addition to the source and target variables, each datapoint can also be associated with a bunch of other independent variables. \n",
      "\n",
      "For example, one of the tasks you can achieve using this script is to study the effect of gender on the probability of student graduation (in this case, gender is the source variable and graduation is the target outcome). In addition, each student might be associated with other indepedent variables such as GPA, absence rates, suspensions etc. \n",
      "\n",
      "In order to tease apart the effect of gender amidst all these variables, we need to make sure that we compare datapoints which are similar on all the other dimensions (except for source and target). We achieve this by clustering similar datapoints together (similarity is a function of all the independent variables which exclude source and target) and then comparing the effect of the source variable on the target outcome. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "What did we use this script for ?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We used this script for studying the effect of gender on student enrollment in colleges, graduation from college and enrollment in selective colleges\n",
      "In addition, we also studied the effect of race on the same set of target outcomes. In addition to the variables of interest, we also had data on each student's GPAs, absence rates, number of suspensions (from Grade 6 to Grade 12)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Input for this script"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Input 1 :- File path containing the data (.csv file). The data file should include a \"source\" and a \"target\" variable (for example, source = gender, target = graduation). Source variable should be a multi-valued or a binary-valued variable. Target variable should be a binary variable (having values 1 or 0; 1 indicates positive, 0 indicates negative). First column in this file should be an index column comprising of a unique id for each data point. The only restriction on all the independent variables is that they should be numeric values. The code removes all the independent variables which have strings as their field values (for ex. school names will be removed before clustering in the code). \n",
      "\n",
      "Input 2 :- Column index for source variable\n",
      "\n",
      "Input 3 :- Column index for target variable\n",
      "\n",
      "Input 4 :- Number of clusters"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Output of this script"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A two dimensional grid (heatmap) with cluster numbers on the rows and the values of the source attribute on the columns. \n",
      "A cell at position (x,y) in the heatmap corresponds to the probability of a positive target outcome for the data points having a source variable value = x and belonging to cluster y. Note that we also \"grey\" out certain cells in this grid and these grey cells indicate the number of samples do not exceed an acceptance sample size (we set the error tolerance rate to 5% Standard Error)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Importing packages"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import pandas as pd\n",
      "from scipy import stats\n",
      "from sklearn import cluster"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Input parameters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# fill in your input values here\n",
      "filename = \"temporaryfile.csv\"\n",
      "sourcecol = 3\n",
      "targetcol = 9\n",
      "num_of_clusters = 10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Reading the input"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# reading input file and printing its size and top few rows\n",
      "df = pd.read_csv(filename,index_col=0,na_values='NA')\n",
      "print df.shape\n",
      "print df.head()\n",
      "print df.columns\n",
      "\n",
      "# put all the columns without source and target variables in X and put source and target variables in separate vectors\n",
      "sourcevec = df.ix[:,sourcecol].tolist()\n",
      "targetvec = df.ix[:,targetcol].tolist()\n",
      "df = df.drop(df.columns[sourcecol],axis=1)\n",
      "df = df.drop(df.columns[targetcol],axis=1)\n",
      "print df.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# dropping all the string attributes if any from the data file \n",
      "  \n",
      "print df.dtypes\n",
      "\n",
      "df = df.replace('None',-1)\n",
      "\n",
      "i = 0\n",
      "while(i<len(df.dtypes)):\n",
      "    if(str(df.dtypes[i]).startswith('object')):\n",
      "        df = df.drop(df.columns[i],axis=1)\n",
      "    else:\n",
      "        i += 1\n",
      "\n",
      "print df.dtypes\n",
      "print df.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Clustering the datapoints "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# in this segment we use all the columns in the data file except for source and target columns to cluster the data points \n",
      "k_means = cluster.KMeans(n_clusters=num_of_clusters)\n",
      "k_means.fit(df)\n",
      "print k_means.labels_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# now inspect your clusters to make sure that you are getting clean and interpretable clusters\n",
      "for i in range(0,num_of_clusters):\n",
      "    df[k_means.labels_==i].hist(xlabelsize=5,ylabelsize=5,figsize=(10,8))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Before you proceed any further, make sure that you are happy with the quality of the clusters you obtained. If the clusters are not interpretable, feel free to split the datapoints based on some thresholds on attribute values."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2-d grid heatmap data computation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "minval = min(sourcevec)\n",
      "\n",
      "l = len(set(sourcevec)) - minval + 1\n",
      "\n",
      "targeted = [[0 for col in range(0,num_of_clusters)] for row in range(0,l)]\n",
      "total = [[0 for col in range(0,num_of_clusters)] for row in range(0,l)]\n",
      "prob = [[0.0 for col in range(0,num_of_clusters)] for row in range(0,l)]\n",
      "\n",
      "X = df.values\n",
      "\n",
      "\n",
      "\n",
      "# count the number of datapoints with positive target outcome in each cell\n",
      "for i in range(0,len(sourcevec)):\n",
      "    source = sourcevec[i] - minval\n",
      "    cnum = k_means.labels_[i]\n",
      "    total[source][cnum] += 1\n",
      "    if(targetvec[i] == 1):\n",
      "        targeted[source][cnum] += 1\n",
      "\n",
      "# compute the probability of positive target outcome for each cell\n",
      "for i in range(0,l):\n",
      "    string = \"\"\n",
      "    for j in range(0,num_of_clusters):\n",
      "        if (total[i][j] == 0):\n",
      "            prob[i][j] = 0.0\n",
      "        else:\n",
      "            prob[i][j] = (targeted[i][j]+0.0)/(total[i][j]+0.0)\n",
      "        string += \"\\t\"+str(prob[i][j])\n",
      "    print string \n",
      "    print \"----\"\n",
      "    \n",
      "# compute the number of datapoints that are required for the sample to give statistically signficant insights \n",
      "p = 0\n",
      "for ele in targetvec:\n",
      "    if (ele==1):\n",
      "        p += 1\n",
      "\n",
      "p = (p+0.0)/len(targetvec)\n",
      "\n",
      "sample_size = p * (1.0 - p) / 0.0025\n",
      "\n",
      "print \"probability is \"+str(p)\n",
      "print \"sample size is \"+str(sample_size)\n",
      "\n",
      "# creating data for heatmap\n",
      "data = []\n",
      "\n",
      "for i in range(0,l):\n",
      "    temp = []\n",
      "    for j in range(0,num_of_clusters):\n",
      "        if (total[i][j] >= sample_size): #5% error rate \n",
      "            temp.append(prob[i][j])\n",
      "        else:\n",
      "            temp.append(np.nan)\n",
      "    data.append(temp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2-d grid heatmap plot"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that the grey cells correspond to cells with sample sizes less than that acceptable to 5% Standard Error"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "ylabels = []\n",
      "for i in range(minval,minval+l):\n",
      "    ylabels.append(str(i))\n",
      "\n",
      "xlabels = []\n",
      "for i in range(0,num_of_clusters):\n",
      "    xlabels.append(str(i))\n",
      "\n",
      "cmap = matplotlib.cm.jet\n",
      "cmap.set_bad('k',0.8)\n",
      "\n",
      "plt.rc('font',**{'family':'serif','serif':['Computer Modern Roman'],'size':12})\n",
      "fig = plt.figure(figsize=(20,12))\n",
      "ax = fig.add_subplot(111)\n",
      "cax = ax.matshow(data, interpolation='nearest')\n",
      "fig.colorbar(cax)\n",
      "ax.set_yticks(np.arange(len(data)), minor=False)\n",
      "ax.set_xticks(np.arange(len(data[0])), minor=False)\n",
      "\n",
      "ax.set_yticklabels(ylabels)\n",
      "ax.set_xticklabels(xlabels)\n",
      "\n",
      "plt.xlabel('Clusters', fontsize=14, color='red')\n",
      "plt.ylabel('Source Attribute', fontsize=14, color='red')\n",
      "\n",
      "for i in range(0,len(data)):\n",
      "    for j in range(0,len(data[0])):\n",
      "        if (not np.isnan(data[i][j])):\n",
      "            plt.text(j - 0.05, i - 0.05, '%.2f' % data[i][j],\n",
      "                 horizontalalignment='center',\n",
      "                 verticalalignment='center'\n",
      "                 )\n",
      "\n",
      "\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}